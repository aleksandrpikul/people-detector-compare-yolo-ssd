# Отчёт: сравнение детекции людей на видео crowd.mp4 (YOLOv8n vs SSD-MobileNetV1)

## 1. Что сравниваем

**Цель:** сравнить качество детекции людей и производительность на одном и том же видеопотоке при одинаковом пайплайне чтения/отрисовки/сохранения.

**Модели:**
1) **YOLOv8n (ONNX, COCO)** — современный одностадийный детектор (быстрый, хорошая точность на мелких объектах).
2) **SSD MobileNetV1 (ONNX, COCO)** — классический одностадийный SSD (очень быстрый и простой, но обычно хуже на плотных толпах и мелких целях).

---

## 2. Методика

- В обоих случаях:
  - читаем `crowd.mp4` через OpenCV
  - для каждого кадра выполняем инференс
  - оставляем **только класс `person`**
  - рисуем bbox + confidence
  - сохраняем выходное видео `mp4`
- Замеряем:
  - среднее время инференса на кадр (`avg_infer_time_s`)
  - p50/p95
  - приблизительный FPS по инференсу (`approx_fps_infer_only`)
  - среднее число людей на кадр (`avg_people_per_frame`) — как индикатор «насколько много находит»
  - среднюю уверенность (`avg_confidence_per_frame`)

---

## 3. Результаты

> Заполните таблицу значениями из:
> - `outputs/crowd_yolov8.mp4.metrics.json`
> - `outputs/crowd_ssd.mp4.metrics.json`

| Модель | avg_infer_time_s | p50 | p95 | approx_fps_infer_only | avg_people_per_frame | avg_confidence_per_frame |
|---|---:|---:|---:|---:|---:|---:|
| YOLOv8n |  |  |  |  |  |  |
| SSD-MobileNetV1 |  |  |  |  |  |  |

---

## 4. Качественное сравнение (что смотреть на видео)

Рекомендуется (и это хорошо видно на crowd-видео) оценивать:
- **Мелкие цели**: насколько уверенно модель находит людей далеко/в глубине сцены.
- **Плотные сцены**: как ведёт себя NMS — «склеивает» ли соседние боксы, теряет ли часть людей.
- **Стабильность**: мигание bbox между кадрами (высокий jitter = плохой пользовательский опыт).
- **Ложные срабатывания**: боксы на фоновые объекты (плакаты/манекены/части сцены).

Обычно:
- YOLOv8n лучше держит плотные толпы и мелких людей (выше recall), но может быть чуть тяжелее.
- SSD-MobileNetV1 часто быстрее на CPU, но чаще пропускает мелких людей и хуже в «толпе».

---

## 5. Выбор предпочтительного алгоритма

**Если важнее качество (не пропускать людей в толпе):** обычно предпочтительнее **YOLOv8n**.  
**Если важнее скорость на слабом CPU и допустимы пропуски:** можно рассмотреть **SSD-MobileNetV1**.

Финальный выбор делайте по вашим метрикам и визуальной проверке: если SSD заметно «режет» количество людей на кадр и пропускает мелкие цели — он хуже подходит для crowd-сцен.

---

## 6. Как улучшить качество и производительность

### 6.1 Улучшение качества
1) **Подстройка порогов**:
   - уменьшить `--conf` (например, 0.25 → 0.15) и/или повысить `--iou` (для YOLO) — осторожно, чтобы не нарастить FP.
2) **Увеличить входное разрешение (YOLO)**:
   - 640 → 768/960, если GPU/CPU позволяет (вырастет recall по мелким людям).
3) **Использовать модель большего размера (YOLOv8s/m/l)**:
   - при наличии ускорителя (GPU).
4) **Трекинг поверх детекции (SORT/ByteTrack)**:
   - сгладить jitter, «восстанавливать» пропуски на соседних кадрах.
5) **Дообучение/файнтюнинг под домен**:
   - если видео сильно отличается от COCO: ракурсы сверху, плохое освещение, специфические камеры.

### 6.2 Улучшение производительности
1) **Аппаратное ускорение**:
   - OpenCV DNN + OpenVINO (Intel), CUDA (если сборка OpenCV поддерживает), TensorRT.
2) **Пакетирование/параллелизм**:
   - декодирование видео и инференс в разных потоках (producer–consumer).
3) **Пропуск кадров / динамический FPS**:
   - детектировать не на каждом кадре (например, 1 из 2–3), а трекером интерполировать.
4) **Квантизация (INT8/FP16)**:
   - особенно эффективно для CPU/edge.
5) **Оптимизированный экспорт модели**:
   - ONNX simplifier, fused NMS, фиксированная размерность входа.

